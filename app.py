from flask import Flask, request, jsonify, send_from_directory, render_template_string
import google.generativeai as genai
import os
import PyPDF2
import io
from docx import Document
from docx.enum.text import WD_ALIGN_PARAGRAPH
import uuid

app = Flask(__name__, static_folder='.', template_folder='.')

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª API
API_KEY = os.environ.get('GEMINI_API_KEY', 'AIzaSyCdRL9mQBAotXCLgyu_BNkaZVu_juL2yok')
genai.configure(api_key=API_KEY)
model = genai.GenerativeModel('gemini-2.0-flash')  # Ù…Ø¯Ù„ Ø¬Ø¯ÛŒØ¯ Ùˆ Ø³Ø±ÛŒØ¹

# Ø°Ø®ÛŒØ±Ù‡ Ù…Ø­ØªÙˆØ§ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
syllabus_content = ""
book_content = ""

@app.route('/')
def index():
    try:
        with open('chatbot_new.html', 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        print(f"Error loading HTML: {e}")
        return """
        <html dir="rtl">
        <head><meta charset="UTF-8"><title>Ø·Ø±Ø­ Ø¯Ø±Ø³ Ø³Ø§Ø²</title></head>
        <body style="font-family: Tahoma; padding: 20px; text-align: center;">
            <h1>ğŸ“ Ø·Ø±Ø­ Ø¯Ø±Ø³ Ø³Ø§Ø² Ø¢Ù†Ù„Ø§ÛŒÙ†</h1>
            <p>Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØµÙØ­Ù‡: """ + str(e) + """</p>
            <p>Ù„Ø·ÙØ§Ù‹ Ú†Ù†Ø¯ Ù„Ø­Ø¸Ù‡ ØµØ¨Ø± Ú©Ù†ÛŒØ¯ Ùˆ ØµÙØ­Ù‡ Ø±Ø§ Ø±ÙØ±Ø´ Ú©Ù†ÛŒØ¯.</p>
        </body>
        </html>
        """

@app.route('/chatbot_new.html')
def chatbot_new():
    return index()

@app.route('/health')
def health():
    """Health check endpoint"""
    return jsonify({
        'status': 'ok',
        'message': 'Ø³Ø±ÙˆÛŒØ³ ÙØ¹Ø§Ù„ Ø§Ø³Øª',
        'api_key_set': bool(os.environ.get('GEMINI_API_KEY')),
        'files_uploaded': {
            'syllabus': bool(syllabus_content),
            'book': bool(book_content)
        }
    })

@app.route('/api/status')
def api_status():
    """ÙˆØ¶Ø¹ÛŒØª API"""
    global syllabus_content, book_content
    return jsonify({
        'status': 'ok',
        'syllabus_uploaded': len(syllabus_content) > 0,
        'book_uploaded': len(book_content) > 0,
        'syllabus_size': len(syllabus_content),
        'book_size': len(book_content),
        'api_key_configured': bool(os.environ.get('GEMINI_API_KEY'))
    })

@app.route('/test_ai')
def test_ai():
    """ØªØ³Øª Ø§ØªØµØ§Ù„ Ø¨Ù‡ Gemini AI"""
    try:
        print("ğŸ”Œ ØªØ³Øª Ø§ØªØµØ§Ù„ Ø¨Ù‡ AI...")
        response = model.generate_content("Ø³Ù„Ø§Ù…")
        print("âœ… Ø§ØªØµØ§Ù„ Ù…ÙˆÙÙ‚!")
        return jsonify({
            'status': 'success',
            'message': 'Ø§ØªØµØ§Ù„ Ø¨Ù‡ AI Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯'
        })
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        })

@app.route('/upload', methods=['POST'])
def upload_files():
    global syllabus_content, book_content
    
    try:
        print("ğŸ“¤ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¢Ù¾Ù„ÙˆØ¯ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯")
        
        if not request.files:
            return jsonify({
                'status': 'error',
                'message': 'Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ÛŒ Ø§Ø±Ø³Ø§Ù„ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª'
            }), 400
        
        syllabus_name = None
        book_name = None
        book_info = {}
        
        if 'syllabus' in request.files:
            syllabus_file = request.files['syllabus']
            if syllabus_file and syllabus_file.filename != '':
                print(f"ğŸ“„ Ø¯Ø± Ø­Ø§Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† Ø·Ø±Ø­ Ø¯Ø±Ø³ Ù†Ù…ÙˆÙ†Ù‡: {syllabus_file.filename}")
                try:
                    syllabus_content = extract_text_from_pdf(syllabus_file)
                    syllabus_name = syllabus_file.filename
                    print(f"âœ“ Ø·Ø±Ø­ Ø¯Ø±Ø³: {len(syllabus_content)} Ú©Ø§Ø±Ø§Ú©ØªØ±")
                except Exception as e:
                    print(f"âœ— Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† Ø·Ø±Ø­ Ø¯Ø±Ø³: {e}")
                    return jsonify({
                        'status': 'error',
                        'message': f'Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Ø·Ø±Ø­ Ø¯Ø±Ø³: {str(e)}'
                    }), 400
        
        if 'book' in request.files:
            book_file = request.files['book']
            if book_file and book_file.filename != '':
                print(f"ğŸ“š Ø¯Ø± Ø­Ø§Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† Ú©Ù„ Ú©ØªØ§Ø¨: {book_file.filename}")
                try:
                    book_content = extract_text_from_pdf(book_file)
                    book_name = book_file.filename
                    print(f"âœ“ Ú©ØªØ§Ø¨: {len(book_content)} Ú©Ø§Ø±Ø§Ú©ØªØ±")
                    
                    # ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ¯Ú©Ø§Ø± Ú©ØªØ§Ø¨
                    print("ğŸ” Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§ÛŒ Ú©ØªØ§Ø¨...")
                    try:
                        book_info = analyze_book_content(book_content)
                    except Exception as e:
                        print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ú©ØªØ§Ø¨: {e}")
                        book_info = {'course_name': 'Ù†Ø§Ù…Ø´Ø®Øµ'}
                except Exception as e:
                    print(f"âœ— Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† Ú©ØªØ§Ø¨: {e}")
                    return jsonify({
                        'status': 'error',
                        'message': f'Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Ú©ØªØ§Ø¨: {str(e)}'
                    }), 400
        
        return jsonify({
            'status': 'success',
            'syllabus_name': syllabus_name,
            'book_name': book_name,
            'book_info': book_info,
            'message': 'ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù†Ø¯'
        })
    except Exception as e:
        print(f"âœ— Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'status': 'error',
            'message': f'Ø®Ø·Ø§ÛŒ Ø³Ø±ÙˆØ±: {str(e)}'
        }), 500

def analyze_book_content(content):
    """ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ¯Ú©Ø§Ø± Ù…Ø­ØªÙˆØ§ÛŒ Ú©ØªØ§Ø¨"""
    try:
        print("  ğŸ¤– Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² AI Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„...")
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² 15000 Ú©Ø§Ø±Ø§Ú©ØªØ± Ø§ÙˆÙ„ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¨Ù‡ØªØ±
        sample_content = content[:15000]
        print(f"  ğŸ“Š Ø·ÙˆÙ„ Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„: {len(sample_content)} Ú©Ø§Ø±Ø§Ú©ØªØ±")
        
        analysis_prompt = f"""
Ù…Ø­ØªÙˆØ§ÛŒ Ú©ØªØ§Ø¨ Ø¯Ø±Ø³ÛŒ (ØµÙØ­Ø§Øª Ø§ÙˆÙ„):
{sample_content}

Ù„Ø·ÙØ§Ù‹ Ø§ÛŒÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø±Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†ÛŒØ¯ Ùˆ Ø¨Ù‡ ØµÙˆØ±Øª JSON Ù¾Ø§Ø³Ø® Ø¯Ù‡ÛŒØ¯:

{{
    "course_name": "Ù†Ø§Ù… Ú©Ø§Ù…Ù„ Ø¯Ø±Ø³",
    "grade": "Ù¾Ø§ÛŒÙ‡ ØªØ­ØµÛŒÙ„ÛŒ",
    "field": "Ø±Ø´ØªÙ‡ ØªØ­ØµÛŒÙ„ÛŒ",
    "chapters_count": ØªØ¹Ø¯Ø§Ø¯ ÙØµÙ„â€ŒÙ‡Ø§,
    "chapters": ["Ø¹Ù†ÙˆØ§Ù† ÙØµÙ„ 1", "Ø¹Ù†ÙˆØ§Ù† ÙØµÙ„ 2"],
    "suggested_request": "ÛŒÚ© Ø·Ø±Ø­ Ø¯Ø±Ø³ Ú©Ø§Ù…Ù„ Ø³Ø§Ù„Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ [Ù†Ø§Ù… Ø¯Ø±Ø³] Ù¾Ø§ÛŒÙ‡ [Ù¾Ø§ÛŒÙ‡] Ø±Ø´ØªÙ‡ [Ø±Ø´ØªÙ‡] Ø¨Ø³Ø§Ø²"
}}

ÙÙ‚Ø· JSON Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒØ¯.
"""
        
        response = model.generate_content(analysis_prompt)
        result_text = response.text
        
        import json
        import re
        
        result_text = re.sub(r'```json\s*', '', result_text)
        result_text = re.sub(r'```\s*', '', result_text)
        
        json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
        if json_match:
            book_info = json.loads(json_match.group())
            print(f"  âœ“ ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø´Ø¯: {book_info.get('course_name', 'Ù†Ø§Ù…Ø´Ø®Øµ')}")
            return book_info
        else:
            print("  âš ï¸ JSON Ù…Ø¹ØªØ¨Ø± Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")
            return {
                'course_name': 'Ù†Ø§Ù…Ø´Ø®Øµ',
                'suggested_request': 'ÛŒÚ© Ø·Ø±Ø­ Ø¯Ø±Ø³ Ú©Ø§Ù…Ù„ Ø³Ø§Ù„Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ú©ØªØ§Ø¨ Ø¨Ø³Ø§Ø²'
            }
    except Exception as e:
        print(f"  âš ï¸ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„: {e}")
        import traceback
        traceback.print_exc()
        return {
            'course_name': 'Ù†Ø§Ù…Ø´Ø®Øµ',
            'suggested_request': 'ÛŒÚ© Ø·Ø±Ø­ Ø¯Ø±Ø³ Ú©Ø§Ù…Ù„ Ø³Ø§Ù„Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ú©ØªØ§Ø¨ Ø¨Ø³Ø§Ø²'
        }

def extract_text_from_pdf(file):
    """Ø®ÙˆØ§Ù†Ø¯Ù† Ú©Ù„ Ù…Ø­ØªÙˆØ§ÛŒ PDF"""
    try:
        pdf_data = file.read()
        pdf_file = io.BytesIO(pdf_data)
        pdf_reader = PyPDF2.PdfReader(pdf_file)
        
        text = ""
        total = len(pdf_reader.pages)
        print(f"  ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ ØµÙØ­Ø§Øª: {total}")
        
        for i, page in enumerate(pdf_reader.pages):
            page_text = page.extract_text()
            if page_text:
                text += page_text + "\n"
            if (i + 1) % 20 == 0:
                print(f"  â³ Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯: {i + 1}/{total}")
        
        print(f"  âœ“ Ú©Ù„ Ù…Ø­ØªÙˆØ§ÛŒ Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯Ù‡: {len(text)} Ú©Ø§Ø±Ø§Ú©ØªØ±")
        
        if len(text) < 100:
            print("  âš ï¸ Ù‡Ø´Ø¯Ø§Ø±: Ù…Ø­ØªÙˆØ§ÛŒ Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯Ù‡ Ø®ÛŒÙ„ÛŒ Ú©Ù… Ø§Ø³Øª!")
            return "Ø®Ø·Ø§: ÙØ§ÛŒÙ„ PDF Ø®Ø§Ù„ÛŒ Ø§Ø³Øª ÛŒØ§ Ù‚Ø§Ø¨Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† Ù†ÛŒØ³Øª"
        
        return text
    except Exception as e:
        print(f"  âœ— Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† PDF: {e}")
        import traceback
        traceback.print_exc()
        return f"Ø®Ø·Ø§: {str(e)}"

def create_table_from_markdown(doc, table_lines):
    """ØªØ¨Ø¯ÛŒÙ„ Ø¬Ø¯ÙˆÙ„ markdown Ø¨Ù‡ Word Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ÙØ§Ø±Ø³ÛŒ"""
    from docx.shared import Pt
    from docx.oxml.ns import qn
    
    if not table_lines:
        return
    
    clean_lines = [line for line in table_lines 
                   if line.strip().replace('|', '').replace('-', '').strip()]
    
    if not clean_lines:
        return
    
    rows = []
    for line in clean_lines:
        cells = [c.strip() for c in line.split('|') if c.strip()]
        if cells:
            rows.append(cells)
    
    if not rows:
        return
    
    max_cols = max(len(row) for row in rows)
    table = doc.add_table(rows=len(rows), cols=max_cols)
    table.style = 'Table Grid'
    
    for i, row_data in enumerate(rows):
        for j, cell_data in enumerate(row_data):
            if j < max_cols:
                cell = table.rows[i].cells[j]
                paragraph = cell.paragraphs[0]
                paragraph.alignment = WD_ALIGN_PARAGRAPH.RIGHT
                
                text = cell_data.replace('<br>', '\n')
                if '**' in text:
                    parts = text.split('**')
                    for k, part in enumerate(parts):
                        run = paragraph.add_run(part)
                        run.font.name = 'B Nazanin'
                        run.font.size = Pt(11)
                        run._element.rPr.rFonts.set(qn('w:cs'), 'B Nazanin')
                        if k % 2 == 1:
                            run.bold = True
                else:
                    run = paragraph.add_run(text)
                    run.font.name = 'B Nazanin'
                    run.font.size = Pt(11)
                    run._element.rPr.rFonts.set(qn('w:cs'), 'B Nazanin')
    
    doc.add_paragraph()

def split_book_into_chunks(content, chunk_size=80000):
    """ØªÙ‚Ø³ÛŒÙ… Ú©ØªØ§Ø¨ Ø¨Ù‡ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©ØªØ±"""
    chunks = []
    for i in range(0, len(content), chunk_size):
        chunks.append(content[i:i + chunk_size])
    return chunks

def extract_book_summary(book_content):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø®Ù„Ø§ØµÙ‡ Ú©Ø§Ù…Ù„ Ú©ØªØ§Ø¨ Ø¨Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú†Ù†Ø¯ Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ"""
    print("ğŸ“š Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø®Ù„Ø§ØµÙ‡ Ú©Ø§Ù…Ù„ Ú©ØªØ§Ø¨...")
    
    # Ø§Ú¯Ø± Ú©ØªØ§Ø¨ Ú©ÙˆÚ†Ú© Ø§Ø³ØªØŒ Ù‡Ù…Ù‡ Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
    if len(book_content) <= 100000:
        print(f"  âœ“ Ú©ØªØ§Ø¨ Ú©ÙˆÚ†Ú© Ø§Ø³Øª ({len(book_content)} Ú©Ø§Ø±Ø§Ú©ØªØ±) - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©Ù„ Ù…Ø­ØªÙˆØ§")
        return book_content
    
    # ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ Ø¨Ø®Ø´â€ŒÙ‡Ø§
    chunks = split_book_into_chunks(book_content, 80000)
    print(f"  ğŸ“Š Ú©ØªØ§Ø¨ Ø¨Ù‡ {len(chunks)} Ø¨Ø®Ø´ ØªÙ‚Ø³ÛŒÙ… Ø´Ø¯")
    
    summaries = []
    for i, chunk in enumerate(chunks):
        print(f"  â³ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø®Ø´ {i+1}/{len(chunks)}...")
        
        prompt = f"""Ù„Ø·ÙØ§Ù‹ Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø§Ø² Ú©ØªØ§Ø¨ Ø¯Ø±Ø³ÛŒ Ø±Ø§ Ø®Ù„Ø§ØµÙ‡ Ú©Ù†ÛŒØ¯ Ùˆ ÙØµÙ„â€ŒÙ‡Ø§ØŒ Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ùˆ Ù…ÙØ§Ù‡ÛŒÙ… Ú©Ù„ÛŒØ¯ÛŒ Ø±Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†ÛŒØ¯:

{chunk[:50000]}

Ø®Ø±ÙˆØ¬ÛŒ: ÙÙ‡Ø±Ø³Øª ÙØµÙ„â€ŒÙ‡Ø§ Ùˆ Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ø¨Ù‡ ØµÙˆØ±Øª Ø®Ù„Ø§ØµÙ‡ Ùˆ Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡
"""
        
        try:
            response = model.generate_content(prompt)
            summaries.append(response.text)
            print(f"    âœ“ Ø¨Ø®Ø´ {i+1} Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯")
        except Exception as e:
            print(f"    âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø®Ø´ {i+1}: {e}")
            summaries.append(chunk[:10000])  # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² 10000 Ú©Ø§Ø±Ø§Ú©ØªØ± Ø§ÙˆÙ„
    
    # ØªØ±Ú©ÛŒØ¨ Ø®Ù„Ø§ØµÙ‡â€ŒÙ‡Ø§
    combined_summary = "\n\n".join(summaries)
    print(f"  âœ“ Ø®Ù„Ø§ØµÙ‡ Ú©Ø§Ù…Ù„ Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯: {len(combined_summary)} Ú©Ø§Ø±Ø§Ú©ØªØ±")
    
    return combined_summary

@app.route('/generate_word', methods=['POST'])
def generate_word():
    global syllabus_content, book_content
    
    try:
        # Ú†Ú© Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
        if not syllabus_content or not book_content:
            return jsonify({
                'status': 'error',
                'message': 'Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ ÙØ§ÛŒÙ„ Ø·Ø±Ø­ Ø¯Ø±Ø³ Ù†Ù…ÙˆÙ†Ù‡ Ùˆ Ú©ØªØ§Ø¨ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯'
            }), 400
        
        data = request.json
        if not data:
            return jsonify({
                'status': 'error',
                'message': 'Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª'
            }), 400
            
        user_message = data.get('message', '')
        first_name = data.get('firstName', '')
        last_name = data.get('lastName', '')
        school_name = data.get('schoolName', '')
        class_day = data.get('classDay', 'Ø´Ù†Ø¨Ù‡')
        hours_per_week = data.get('hoursPerWeek', '8')
        holidays = data.get('holidays', '')
        
        print(f"\n{'='*60}")
        print(f"ğŸ“ Ø¯Ø±Ø®ÙˆØ§Ø³Øª: {user_message}")
        print(f"ğŸ‘¤ Ù†Ø§Ù…: {first_name} {last_name}")
        print(f"ğŸ« Ù…Ø¯Ø±Ø³Ù‡: {school_name}")
        # ØªØ¹Ø·ÛŒÙ„Ø§Øª Ø±Ø³Ù…ÛŒ Ø§ÛŒØ±Ø§Ù†
        holidays = """
ØªØ¹Ø·ÛŒÙ„Ø§Øª Ø±Ø³Ù…ÛŒ Ø³Ø§Ù„ ØªØ­ØµÛŒÙ„ÛŒ:
- 22 Ø¨Ù‡Ù…Ù†: Ù¾ÛŒØ±ÙˆØ²ÛŒ Ø§Ù†Ù‚Ù„Ø§Ø¨ Ø§Ø³Ù„Ø§Ù…ÛŒ (ØªØ¹Ø·ÛŒÙ„)
- 29 Ø§Ø³ÙÙ†Ø¯: Ø±ÙˆØ² Ù…Ù„ÛŒ Ø´Ø¯Ù† ØµÙ†Ø¹Øª Ù†ÙØª (ØªØ¹Ø·ÛŒÙ„)
- 1-4 ÙØ±ÙˆØ±Ø¯ÛŒÙ†: Ø¹ÛŒØ¯ Ù†ÙˆØ±ÙˆØ² (ØªØ¹Ø·ÛŒÙ„)
- 12-13 ÙØ±ÙˆØ±Ø¯ÛŒÙ†: Ø±ÙˆØ² Ø·Ø¨ÛŒØ¹Øª (ØªØ¹Ø·ÛŒÙ„)
- 14 Ø®Ø±Ø¯Ø§Ø¯: Ø±Ø­Ù„Øª Ø§Ù…Ø§Ù… Ø®Ù…ÛŒÙ†ÛŒ (ØªØ¹Ø·ÛŒÙ„)
- 15 Ø®Ø±Ø¯Ø§Ø¯: Ù‚ÛŒØ§Ù… 15 Ø®Ø±Ø¯Ø§Ø¯ (ØªØ¹Ø·ÛŒÙ„)
- ØªØ¹Ø·ÛŒÙ„Ø§Øª Ù…Ø°Ù‡Ø¨ÛŒ: Ø´Ù‡Ø§Ø¯Øª Ø§Ù…Ø§Ù… Ø¹Ù„ÛŒØŒ Ø¹ÛŒØ¯ ÙØ·Ø±ØŒ Ø¹ÛŒØ¯ Ù‚Ø±Ø¨Ø§Ù†ØŒ ØªØ§Ø³ÙˆØ¹Ø§ Ùˆ Ø¹Ø§Ø´ÙˆØ±Ø§ (ØªØ§Ø±ÛŒØ® Ù…ØªØºÛŒØ±)
- ØªØ¹Ø·ÛŒÙ„Ø§Øª Ù†ÛŒÙ…Ø³Ø§Ù„: 15 Ø¯ÛŒ ØªØ§ 24 Ø¯ÛŒ (10 Ø±ÙˆØ²)
- Ù¾Ù†Ø¬Ø´Ù†Ø¨Ù‡â€ŒÙ‡Ø§ Ùˆ Ø¬Ù…Ø¹Ù‡â€ŒÙ‡Ø§: ØªØ¹Ø·ÛŒÙ„ Ù‡ÙØªÚ¯ÛŒ
"""
        
        print(f"ğŸ“… Ø±ÙˆØ² Ú©Ù„Ø§Ø³: {class_day}")
        print(f"â° Ø³Ø§Ø¹Øª: {hours_per_week}")
        print(f"ğŸ“Š Ø·ÙˆÙ„ Ù…Ø­ØªÙˆØ§ÛŒ Ú©ØªØ§Ø¨: {len(book_content)} Ú©Ø§Ø±Ø§Ú©ØªØ±")
        print(f"ğŸ“Š Ø·ÙˆÙ„ Ø·Ø±Ø­ Ø¯Ø±Ø³ Ù†Ù…ÙˆÙ†Ù‡: {len(syllabus_content)} Ú©Ø§Ø±Ø§Ú©ØªØ±")
        print(f"{'='*60}")
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø®Ù„Ø§ØµÙ‡ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø§Ø² Ú©Ù„ Ú©ØªØ§Ø¨
        print("ğŸ”„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ú©ØªØ§Ø¨...")
        book_summary = extract_book_summary(book_content)
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø§Ù„ ØªØ­ØµÛŒÙ„ÛŒ Ø¬Ø§Ø±ÛŒ
        import jdatetime
        today = jdatetime.datetime.now()
        # Ø§Ú¯Ø± Ù…Ø§Ù‡ 1 ØªØ§ 6 Ø¨Ø§Ø´Ù‡ (ÙØ±ÙˆØ±Ø¯ÛŒÙ† ØªØ§ Ø´Ù‡Ø±ÛŒÙˆØ±)ØŒ Ø³Ø§Ù„ Ù‚Ø¨Ù„ Ø´Ø±ÙˆØ¹ Ø´Ø¯Ù‡
        # Ø§Ú¯Ø± Ù…Ø§Ù‡ 7 ØªØ§ 12 Ø¨Ø§Ø´Ù‡ (Ù…Ù‡Ø± ØªØ§ Ø§Ø³ÙÙ†Ø¯)ØŒ Ø³Ø§Ù„ Ø¬Ø§Ø±ÛŒ Ø´Ø±ÙˆØ¹ Ø´Ø¯Ù‡
        if today.month <= 6:
            current_year = today.year - 1
        else:
            current_year = today.year
        next_year = current_year + 1
        
        print(f"ğŸ“… Ø³Ø§Ù„ ØªØ­ØµÛŒÙ„ÛŒ: {current_year}-{next_year}")
        
        prompt = f"""Ø´Ù…Ø§ Ù…ØªØ®ØµØµ Ø·Ø±Ø§Ø­ÛŒ Ø·Ø±Ø­ Ø¯Ø±Ø³ Ù‡Ø³ØªÛŒØ¯.

Ø·Ø±Ø­ Ø¯Ø±Ø³ Ù†Ù…ÙˆÙ†Ù‡ (Ø³Ø§Ø®ØªØ§Ø± Ø¯Ù‚ÛŒÙ‚ - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©Ù„ Ù…Ø­ØªÙˆØ§):
{syllabus_content}

Ù…Ø­ØªÙˆØ§ÛŒ Ú©Ø§Ù…Ù„ Ú©ØªØ§Ø¨ Ø¯Ø±Ø³ÛŒ (Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡):
{book_summary}

Ø¯Ø±Ø®ÙˆØ§Ø³Øª: {user_message}

Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø¹Ù„Ù… Ùˆ Ù…Ø¯Ø±Ø³Ù‡:
- Ù†Ø§Ù… Ù…Ø¹Ù„Ù…: {first_name} {last_name}
- Ù†Ø§Ù… Ù…Ø¯Ø±Ø³Ù‡: {school_name}
- Ø±ÙˆØ² Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ Ú©Ù„Ø§Ø³: {class_day}
- ØªØ¹Ø¯Ø§Ø¯ Ø³Ø§Ø¹Øª Ø¯Ø± Ù‡ÙØªÙ‡: {hours_per_week} Ø³Ø§Ø¹Øª
- ØªØ¹Ø·ÛŒÙ„Ø§Øª Ø±Ø³Ù…ÛŒ: {holidays if holidays else 'Ø¨Ø¯ÙˆÙ† ØªØ¹Ø·ÛŒÙ„Ø§Øª Ø®Ø§Øµ'}

Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ù…Ù‡Ù…:
1. Ø¯Ø± Ø³Ø±ØµÙØ­Ù‡ Ø§ÛŒÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø±Ø§ Ù‚ÛŒØ¯ Ú©Ù†ÛŒØ¯:
   - Ù†Ø§Ù… Ù…Ø¹Ù„Ù…: {first_name} {last_name}
   - Ù†Ø§Ù… Ù…Ø¯Ø±Ø³Ù‡: {school_name}
   - Ø±ÙˆØ² Ú©Ù„Ø§Ø³: {class_day}
   - Ø³Ø§Ø¹Øª Ù‡ÙØªÚ¯ÛŒ: {hours_per_week} Ø³Ø§Ø¹Øª
2. Ø·Ø±Ø­ Ø¯Ø±Ø³ Ø±Ø§ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ù…Ø«Ù„ Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø³Ø§Ø²ÛŒØ¯
3. Ø§Ø² ØªÙ…Ø§Ù… Ù…Ø­ØªÙˆØ§ÛŒ Ú©ØªØ§Ø¨ Ø¨Ø±Ø§ÛŒ ØªØ¹ÛŒÛŒÙ† Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ùˆ ÙØµÙ„â€ŒÙ‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
4. Ù‡Ù…Ù‡ Ù…Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ù„ ØªØ­ØµÛŒÙ„ÛŒ Ø±Ø§ Ù¾ÙˆØ´Ø´ Ø¯Ù‡ÛŒØ¯: Ù…Ù‡Ø±ØŒ Ø¢Ø¨Ø§Ù†ØŒ Ø¢Ø°Ø±ØŒ Ø¯ÛŒØŒ Ø¨Ù‡Ù…Ù†ØŒ Ø§Ø³ÙÙ†Ø¯ØŒ ÙØ±ÙˆØ±Ø¯ÛŒÙ†ØŒ Ø§Ø±Ø¯ÛŒØ¨Ù‡Ø´ØªØŒ Ø®Ø±Ø¯Ø§Ø¯
5. Ø¨Ø±Ø§ÛŒ Ù‡Ø± {class_day} ÛŒÚ© Ø±Ø¯ÛŒÙ Ø¬Ø¯ÙˆÙ„ Ø¨Ø³Ø§Ø²ÛŒØ¯ (Ø§Ø² Ø§ÙˆÙ„ Ù…Ù‡Ø± Ø³Ø§Ù„ Ø¬Ø§Ø±ÛŒ ØªØ§ Ø¢Ø®Ø± Ø®Ø±Ø¯Ø§Ø¯ Ø³Ø§Ù„ Ø¨Ø¹Ø¯)
6. ÙØ±Ù…Øª Ø¬Ø¯ÙˆÙ„: | Ù…Ø§Ù‡ | ØªØ§Ø±ÛŒØ® Ú©Ø§Ù…Ù„ | Ø³Ø§Ø¹Øª | Ø¹Ù†ÙˆØ§Ù† | Ø§Ù‡Ø¯Ø§Ù | ÙØ¹Ø§Ù„ÛŒØªÙ‡Ø§ | ØªÙˆØ¶ÛŒØ­Ø§Øª |
7. Ø³Ø§Ù„ ØªØ­ØµÛŒÙ„ÛŒ Ø¬Ø§Ø±ÛŒ: {current_year} (Ù…Ù‡Ø± ØªØ§ Ø§Ø³ÙÙ†Ø¯) Ùˆ {next_year} (ÙØ±ÙˆØ±Ø¯ÛŒÙ† ØªØ§ Ø®Ø±Ø¯Ø§Ø¯)
8. Ø¯Ø± Ø³ØªÙˆÙ† "ØªØ§Ø±ÛŒØ® Ú©Ø§Ù…Ù„" ÙÙ‚Ø· Ø±ÙˆØ² Ø§Ù†ØªØ®Ø§Ø¨ÛŒ ({class_day}) Ùˆ ØªØ§Ø±ÛŒØ® Ø¢Ù† Ø±ÙˆØ² Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯
9. ÙØ±Ù…Øª Ø¯Ù‚ÛŒÙ‚: {class_day} Ø³Ø§Ù„/Ù…Ø§Ù‡/Ø±ÙˆØ² (Ù…Ø«Ù„Ø§Ù‹: {class_day} {current_year}/7/1)
10. Ù…Ù‡Ù…: Ø±ÙˆØ² Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ú©Ø§Ø±Ø¨Ø± "{class_day}" Ø§Ø³Øª. ÙÙ‚Ø· Ø§ÛŒÙ† Ø±ÙˆØ² Ø±Ø§ Ø¯Ø± Ø¬Ø¯ÙˆÙ„ Ø¨ÛŒØ§ÙˆØ±ÛŒØ¯.
11. Ø±ÙˆØ² Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ú©Ø§Ø±Ø¨Ø±: {class_day}
12. Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± "Ø¯ÙˆØ´Ù†Ø¨Ù‡" Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø±Ø¯Ù‡ØŒ ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§ÛŒ Ø¯ÙˆØ´Ù†Ø¨Ù‡ Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯ (Ù†Ù‡ Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡!)
13. Ø¯Ø± Ø³ØªÙˆÙ† "ØªØ§Ø±ÛŒØ® Ú©Ø§Ù…Ù„" Ø±ÙˆØ² Ù‡ÙØªÙ‡ Ùˆ ØªØ§Ø±ÛŒØ® Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯
14. ÙØ±Ù…Øª: {class_day} Ø³Ø§Ù„/Ù…Ø§Ù‡/Ø±ÙˆØ²
15. ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§ÛŒ {class_day} Ø¯Ø± Ø³Ø§Ù„ {current_year}:
    - Ø§Ú¯Ø± Ø¯ÙˆØ´Ù†Ø¨Ù‡: Ù…Ù‡Ø± 7ØŒ 14ØŒ 21ØŒ 28 (ÛŒØ¹Ù†ÛŒ {current_year}/7/7ØŒ {current_year}/7/14ØŒ {current_year}/7/21ØŒ {current_year}/7/28)
    - Ø§Ú¯Ø± Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡: Ù…Ù‡Ø± 1ØŒ 8ØŒ 15ØŒ 22ØŒ 29 (ÛŒØ¹Ù†ÛŒ {current_year}/7/1ØŒ {current_year}/7/8ØŒ {current_year}/7/15ØŒ {current_year}/7/22ØŒ {current_year}/7/29)
    - Ø§Ú¯Ø± Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡: Ù…Ù‡Ø± 2ØŒ 9ØŒ 16ØŒ 23ØŒ 30 (ÛŒØ¹Ù†ÛŒ {current_year}/7/2ØŒ {current_year}/7/9ØŒ {current_year}/7/16ØŒ {current_year}/7/23ØŒ {current_year}/7/30)
16. Ù…Ø«Ø§Ù„ Ø¨Ø±Ø§ÛŒ Ø¯ÙˆØ´Ù†Ø¨Ù‡:
    | Ù…Ù‡Ø± | Ø¯ÙˆØ´Ù†Ø¨Ù‡ {current_year}/7/7 | 8 | ÙØµÙ„ Ø§ÙˆÙ„ | ...
    | Ù…Ù‡Ø± | Ø¯ÙˆØ´Ù†Ø¨Ù‡ {current_year}/7/14 | 8 | Ø§Ø¯Ø§Ù…Ù‡ | ...
    | Ù…Ù‡Ø± | Ø¯ÙˆØ´Ù†Ø¨Ù‡ {current_year}/7/21 | 8 | ÙØµÙ„ Ø¯ÙˆÙ… | ...
17. Ù…Ø«Ø§Ù„ Ø¨Ø±Ø§ÛŒ Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡:
    | Ù…Ù‡Ø± | Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡ {current_year}/7/1 | 8 | ÙØµÙ„ Ø§ÙˆÙ„ | ...
    | Ù…Ù‡Ø± | Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡ {current_year}/7/8 | 8 | Ø§Ø¯Ø§Ù…Ù‡ | ...
18. Ø¯Ø± Ø³ØªÙˆÙ† Ø³Ø§Ø¹ØªØŒ Ø§Ø² {hours_per_week} Ø³Ø§Ø¹Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
19. Ù…Ù‡Ù…: Ø­ØªÙ…Ø§Ù‹ Ø±ÙˆØ² Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ú©Ø§Ø±Ø¨Ø± ({class_day}) Ø±Ø§ Ø¯Ø± Ù†Ø¸Ø± Ø¨Ú¯ÛŒØ±ÛŒØ¯!
9. ØªØ¹Ø·ÛŒÙ„Ø§Øª Ø±Ø³Ù…ÛŒ Ø±Ø§ Ø¯Ø± Ù†Ø¸Ø± Ø¨Ú¯ÛŒØ±ÛŒØ¯ Ùˆ Ø¯Ø± Ø¢Ù† Ø±ÙˆØ²Ù‡Ø§ Ù‡ÛŒÚ† Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ§ÛŒ Ù†Ù†ÙˆÛŒØ³ÛŒØ¯
10. Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ²Ù‡Ø§ÛŒ ØªØ¹Ø·ÛŒÙ„ØŒ ÙÙ‚Ø· ÛŒÚ© Ø±Ø¯ÛŒÙ Ø®Ø§Ù„ÛŒ Ø¨Ø§ "ØªØ¹Ø·ÛŒÙ„ Ø±Ø³Ù…ÛŒ - [Ù†Ø§Ù… ØªØ¹Ø·ÛŒÙ„Ø§Øª]" Ø¯Ø± Ø³ØªÙˆÙ† ØªÙˆØ¶ÛŒØ­Ø§Øª Ø¨Ú¯Ø°Ø§Ø±ÛŒØ¯
11. ØªØ¹Ø·ÛŒÙ„Ø§Øª Ù†ÛŒÙ…Ø³Ø§Ù„ (15-24 Ø¯ÛŒ) Ø±Ø§ Ú©Ø§Ù…Ù„Ø§Ù‹ Ø®Ø§Ù„ÛŒ Ø¨Ú¯Ø°Ø§Ø±ÛŒØ¯
12. Ø¬Ø¯ÙˆÙ„ Ø¨Ø§ÛŒØ¯ Ú©Ø§Ù…Ù„ Ùˆ Ø¬Ø§Ù…Ø¹ Ø¨Ø§Ø´Ø¯ Ùˆ ØªÙ…Ø§Ù… ÙØµÙ„â€ŒÙ‡Ø§ÛŒ Ú©ØªØ§Ø¨ Ø±Ø§ Ù¾ÙˆØ´Ø´ Ø¯Ù‡Ø¯

Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø§ÛŒØ¯ Ø´Ø§Ù…Ù„:
- Ø¨Ø¯ÙˆÙ† Ù‡ÛŒÚ† Ù…Ù‚Ø¯Ù…Ù‡ ÛŒØ§ ØªÙˆØ¶ÛŒØ­ Ø§Ø¶Ø§ÙÛŒØŒ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¨Ø§ Ø³Ø±ØµÙØ­Ù‡ Ø´Ø±ÙˆØ¹ Ú©Ù†ÛŒØ¯
- Ø³Ø±ØµÙØ­Ù‡ (Ù†Ø§Ù… Ø¯Ø±Ø³ØŒ Ù¾Ø§ÛŒÙ‡ØŒ Ø±Ø´ØªÙ‡ØŒ Ù†Ø§Ù… Ù…Ø¹Ù„Ù…ØŒ Ù†Ø§Ù… Ù…Ø¯Ø±Ø³Ù‡ØŒ Ø±ÙˆØ² Ú©Ù„Ø§Ø³: {class_day}ØŒ Ø³Ø§Ø¹Øª Ù‡ÙØªÚ¯ÛŒØŒ Ø³Ø§Ù„ ØªØ­ØµÛŒÙ„ÛŒ {current_year}-{next_year})
- Ø¬Ø¯ÙˆÙ„ Ú©Ø§Ù…Ù„ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø³Ø§Ù„Ø§Ù†Ù‡ Ø¨Ø§ Ø±ÙˆØ² Ù‡ÙØªÙ‡ Ùˆ ØªØ§Ø±ÛŒØ®
- ÙØ±Ù…Øª Ø³ØªÙˆÙ† ØªØ§Ø±ÛŒØ®: {class_day} Ø³Ø§Ù„/Ù…Ø§Ù‡/Ø±ÙˆØ²
- Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ø¯ÙˆØ´Ù†Ø¨Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø±Ø¯Ù‡ØŒ Ù…Ø«Ø§Ù„ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§:
    | Ù…Ù‡Ø± | Ø¯ÙˆØ´Ù†Ø¨Ù‡ {current_year}/7/7 | 8 | ÙØµÙ„ Ø§ÙˆÙ„ | ...
    | Ù…Ù‡Ø± | Ø¯ÙˆØ´Ù†Ø¨Ù‡ {current_year}/7/14 | 8 | Ø§Ø¯Ø§Ù…Ù‡ | ...
    | Ù…Ù‡Ø± | Ø¯ÙˆØ´Ù†Ø¨Ù‡ {current_year}/7/21 | 8 | ÙØµÙ„ Ø¯ÙˆÙ… | ...
- Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø±Ø¯Ù‡ØŒ Ù…Ø«Ø§Ù„ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§:
    | Ù…Ù‡Ø± | Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡ {current_year}/7/1 | 8 | ÙØµÙ„ Ø§ÙˆÙ„ | ...
    | Ù…Ù‡Ø± | Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡ {current_year}/7/8 | 8 | Ø§Ø¯Ø§Ù…Ù‡ | ...
- ØªØ¹Ø·ÛŒÙ„Ø§Øª Ù†ÛŒÙ…Ø³Ø§Ù„ (15-24 Ø¯ÛŒ) Ø±Ø§ Ú©Ø§Ù…Ù„Ø§Ù‹ Ø®Ø§Ù„ÛŒ Ø¨Ú¯Ø°Ø§Ø±ÛŒØ¯
- Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ Ùˆ ÙˆØ³Ø§ÛŒÙ„ Ø¢Ù…ÙˆØ²Ø´ÛŒ
- Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø²Ø´ÛŒØ§Ø¨ÛŒ
- Ù…Ù†Ø§Ø¨Ø¹ Ùˆ Ù…Ø±Ø§Ø¬Ø¹

Ù…Ù‡Ù…: 
1. Ù‡ÛŒÚ† Ø¬Ù…Ù„Ù‡ ØªÙˆØ¶ÛŒØ­ÛŒ Ù…Ø§Ù†Ù†Ø¯ "Ø¨Ø³ÛŒØ§Ø± Ø®Ø¨ØŒ Ø§ÛŒÙ† ÛŒÚ© Ø·Ø±Ø­ Ø¯Ø±Ø³..." Ù†Ù†ÙˆÛŒØ³ÛŒØ¯
2. Ø­ØªÙ…Ø§Ù‹ Ø±ÙˆØ² Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ú©Ø§Ø±Ø¨Ø± ({class_day}) Ø±Ø§ Ø¯Ø± Ø¬Ø¯ÙˆÙ„ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯
3. Ø§Ú¯Ø± Ø¯ÙˆØ´Ù†Ø¨Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ØŒ ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§ÛŒ Ø¯ÙˆØ´Ù†Ø¨Ù‡ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯ (7ØŒ 14ØŒ 21ØŒ 28)
4. Ø§Ú¯Ø± Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ØŒ ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§ÛŒ Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯ (1ØŒ 8ØŒ 15ØŒ 22ØŒ 29)
"""

        print("ğŸ¤– Ø¯Ø± Ø­Ø§Ù„ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ Gemini AI...")
        response = model.generate_content(prompt)
        syllabus_text = response.text
        print(f"âœ“ Ù¾Ø§Ø³Ø® Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯: {len(syllabus_text)} Ú©Ø§Ø±Ø§Ú©ØªØ±")
        
        print("ğŸ“„ Ø¯Ø± Ø­Ø§Ù„ Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Word...")
        doc = Document()
        
        lines = syllabus_text.split('\n')
        in_table = False
        table_lines = []
        
        for line in lines:
            if '|' in line and line.strip().startswith('|'):
                if not in_table:
                    in_table = True
                    table_lines = []
                table_lines.append(line)
            else:
                if in_table and table_lines:
                    create_table_from_markdown(doc, table_lines)
                    in_table = False
                    table_lines = []
                
                if line.strip():
                    paragraph = doc.add_paragraph()
                    paragraph.alignment = WD_ALIGN_PARAGRAPH.RIGHT
                    
                    if '**' in line:
                        parts = line.split('**')
                        for i, part in enumerate(parts):
                            run = paragraph.add_run(part)
                            if i % 2 == 1:
                                run.bold = True
                    else:
                        paragraph.add_run(line)
        
        if in_table and table_lines:
            create_table_from_markdown(doc, table_lines)
        
        filename = f"Ø·Ø±Ø­_Ø¯Ø±Ø³_{uuid.uuid4().hex[:8]}.docx"
        filepath = os.path.join("generated", filename)
        
        if not os.path.exists("generated"):
            os.makedirs("generated")
        
        doc.save(filepath)
        print(f"âœ“ ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {filename}\n")
        
        return jsonify({
            'status': 'success',
            'content': syllabus_text,
            'filename': filename,
            'message': 'Ø·Ø±Ø­ Ø¯Ø±Ø³ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯'
        })
    except Exception as e:
        print(f"âœ— Ø®Ø·Ø§: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'status': 'error', 'message': str(e)})

@app.route('/export', methods=['POST'])
def export_file():
    """ØªÙˆÙ„ÛŒØ¯ ÙØ§ÛŒÙ„ Ø¨Ø§ ÙØ±Ù…Øª Ø¯Ù„Ø®ÙˆØ§Ù‡"""
    try:
        data = request.json
        content = data.get('content', '')
        format_type = data.get('format', 'word')
        
        print(f"ğŸ“¤ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ ÙØ§ÛŒÙ„ {format_type.upper()}...")
        
        filename_base = f"Ø·Ø±Ø­_Ø¯Ø±Ø³_{uuid.uuid4().hex[:8]}"
        
        if format_type == 'pdf':
            filename = f"{filename_base}.pdf"
            filepath = create_pdf_file(content, filename)
        elif format_type == 'word':
            filename = f"{filename_base}.docx"
            filepath = create_word_file(content, filename)
        elif format_type == 'excel':
            filename = f"{filename_base}.xlsx"
            filepath = create_excel_file(content, filename)
        elif format_type == 'html':
            filename = f"{filename_base}.html"
            filepath = create_html_file(content, filename)
        else:
            return jsonify({'status': 'error', 'message': 'ÙØ±Ù…Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø±'})
        
        print(f"âœ“ ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {filename}")
        
        return jsonify({
            'status': 'success',
            'filename': filename,
            'message': f'ÙØ§ÛŒÙ„ {format_type.upper()} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯'
        })
    except Exception as e:
        print(f"âœ— Ø®Ø·Ø§: {e}")
        return jsonify({'status': 'error', 'message': str(e)})

def create_word_file(content, filename):
    """Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Word Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ú©Ø§Ù…Ù„ Ø§Ø² ÙØ§Ø±Ø³ÛŒ"""
    from docx.shared import Pt, RGBColor
    from docx.oxml.ns import qn
    
    doc = Document()
    
    # ØªÙ†Ø¸ÛŒÙ… ÙÙˆÙ†Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ
    style = doc.styles['Normal']
    font = style.font
    font.name = 'B Nazanin'
    font.size = Pt(12)
    
    # ØªÙ†Ø¸ÛŒÙ… ÙÙˆÙ†Øª Ø¨Ø±Ø§ÛŒ Ø²Ø¨Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ (ÙØ§Ø±Ø³ÛŒ/Ø¹Ø±Ø¨ÛŒ)
    rFonts = style.element.rPr.rFonts
    rFonts.set(qn('w:eastAsia'), 'B Nazanin')
    rFonts.set(qn('w:cs'), 'B Nazanin')
    
    lines = content.split('\n')
    in_table = False
    table_lines = []
    
    for line in lines:
        if '|' in line and line.strip().startswith('|'):
            if not in_table:
                in_table = True
                table_lines = []
            table_lines.append(line)
        else:
            if in_table and table_lines:
                create_table_from_markdown(doc, table_lines)
                in_table = False
                table_lines = []
            
            if line.strip():
                paragraph = doc.add_paragraph()
                paragraph.alignment = WD_ALIGN_PARAGRAPH.RIGHT
                
                if '**' in line:
                    parts = line.split('**')
                    for i, part in enumerate(parts):
                        run = paragraph.add_run(part)
                        run.font.name = 'B Nazanin'
                        run.font.size = Pt(12)
                        run._element.rPr.rFonts.set(qn('w:cs'), 'B Nazanin')
                        if i % 2 == 1:
                            run.bold = True
                else:
                    run = paragraph.add_run(line)
                    run.font.name = 'B Nazanin'
                    run.font.size = Pt(12)
                    run._element.rPr.rFonts.set(qn('w:cs'), 'B Nazanin')
    
    if in_table and table_lines:
        create_table_from_markdown(doc, table_lines)
    
    filepath = os.path.join("generated", filename)
    if not os.path.exists("generated"):
        os.makedirs("generated")
    
    doc.save(filepath)
    return filepath

def create_excel_file(content, filename):
    """Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Excel"""
    import openpyxl
    from openpyxl.styles import Font, Alignment, PatternFill
    
    wb = openpyxl.Workbook()
    ws = wb.active
    ws.title = "Ø·Ø±Ø­ Ø¯Ø±Ø³"
    
    lines = content.split('\n')
    row = 1
    
    for line in lines:
        if '|' in line and line.strip().startswith('|'):
            cells = [c.strip() for c in line.split('|') if c.strip()]
            for col, cell_data in enumerate(cells, 1):
                cell = ws.cell(row=row, column=col, value=cell_data)
                cell.alignment = Alignment(horizontal='right', vertical='top', wrap_text=True)
                
                if row == 1:
                    cell.font = Font(bold=True, color="FFFFFF")
                    cell.fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
            row += 1
        elif line.strip() and not line.strip().replace('-', ''):
            continue
        elif line.strip():
            ws.cell(row=row, column=1, value=line.strip())
            row += 1
    
    filepath = os.path.join("generated", filename)
    wb.save(filepath)
    return filepath

def create_html_file(content, filename):
    """Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ HTML"""
    import markdown
    html_content = markdown.markdown(content, extensions=['tables'])
    
    html_template = f"""<!DOCTYPE html>
<html dir="rtl" lang="fa">
<head>
    <meta charset="UTF-8">
    <title>Ø·Ø±Ø­ Ø¯Ø±Ø³</title>
    <style>
        body {{ font-family: Tahoma; padding: 20px; direction: rtl; text-align: right; }}
        table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
        th, td {{ border: 1px solid #ddd; padding: 12px; text-align: right; }}
        th {{ background: #4472C4; color: white; }}
    </style>
</head>
<body>
    {html_content}
</body>
</html>"""
    
    filepath = os.path.join("generated", filename)
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(html_template)
    
    return filepath

def create_pdf_file(content, filename):
    """Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ PDF Ø§Ø² HTML Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ÙØ§Ø±Ø³ÛŒ"""
    try:
        from weasyprint import HTML, CSS
        from weasyprint.text.fonts import FontConfiguration
        
        # Ø§ÛŒØ¬Ø§Ø¯ HTML Ø¨Ø§ ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ
        html_content = f"""<!DOCTYPE html>
<html dir="rtl" lang="fa">
<head>
    <meta charset="UTF-8">
    <style>
        @page {{
            size: A4;
            margin: 2cm;
        }}
        body {{
            font-family: 'Tahoma', 'Arial', sans-serif;
            direction: rtl;
            text-align: right;
            line-height: 1.8;
            font-size: 12pt;
        }}
        h1, h2, h3 {{
            color: #2c3e50;
            margin: 15px 0;
        }}
        table {{
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            font-size: 10pt;
        }}
        th, td {{
            border: 1px solid #ddd;
            padding: 8px;
            text-align: right;
        }}
        th {{
            background-color: #4472C4;
            color: white;
            font-weight: bold;
        }}
        tr:nth-child(even) {{
            background-color: #f9f9f9;
        }}
        .header {{
            text-align: center;
            margin-bottom: 30px;
            padding-bottom: 20px;
            border-bottom: 2px solid #4472C4;
        }}
    </style>
</head>
<body>
    <div class="header">
        <h1>Ø·Ø±Ø­ Ø¯Ø±Ø³ Ø³Ø§Ù„Ø§Ù†Ù‡</h1>
    </div>
    <pre style="white-space: pre-wrap; font-family: Tahoma;">{content}</pre>
</body>
</html>"""
        
        filepath = os.path.join("generated", filename)
        
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙÙˆÙ†Øª
        font_config = FontConfiguration()
        
        # ØªØ¨Ø¯ÛŒÙ„ HTML Ø¨Ù‡ PDF
        HTML(string=html_content).write_pdf(
            filepath,
            font_config=font_config
        )
        
        return filepath
        
    except ImportError:
        # Ø§Ú¯Ø± weasyprint Ù†ØµØ¨ Ù†ÛŒØ³ØªØŒ Ø§Ø² Ø±ÙˆØ´ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
        print("âš ï¸ weasyprint Ù†ØµØ¨ Ù†ÛŒØ³ØªØŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ´ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†...")
        return create_pdf_from_word(content, filename)

def create_pdf_from_word(content, filename):
    """Ø§ÛŒØ¬Ø§Ø¯ PDF Ø§Ø² Ø·Ø±ÛŒÙ‚ Word (Ø±ÙˆØ´ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†)"""
    try:
        # Ø§Ø¨ØªØ¯Ø§ Word Ø¨Ø³Ø§Ø²
        word_filename = filename.replace('.pdf', '.docx')
        word_filepath = create_word_file(content, word_filename)
        
        # Ø³Ø¹ÛŒ Ú©Ù† Word Ø±Ø§ Ø¨Ù‡ PDF ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†ÛŒ
        try:
            from docx2pdf import convert
            pdf_filepath = word_filepath.replace('.docx', '.pdf')
            convert(word_filepath, pdf_filepath)
            return pdf_filepath
        except:
            # Ø§Ú¯Ø± Ù†Ø´Ø¯ØŒ ÙÙ‚Ø· ÙØ§ÛŒÙ„ Word Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
            print("âš ï¸ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ PDF Ù…Ù…Ú©Ù† Ù†ÛŒØ³ØªØŒ ÙØ§ÛŒÙ„ Word Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯")
            return word_filepath
            
    except Exception as e:
        print(f"âœ— Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ PDF: {e}")
        # Ø¯Ø± Ù†Ù‡Ø§ÛŒØª HTML Ø¨Ø³Ø§Ø²
        return create_html_file(content, filename.replace('.pdf', '.html'))

@app.route('/download/<filename>')
def download_file(filename):
    try:
        return send_from_directory('generated', filename, as_attachment=True)
    except Exception as e:
        return str(e), 404

if __name__ == '__main__':
    os.makedirs('generated', exist_ok=True)
    port = int(os.environ.get('PORT', 5000))
    app.run(debug=False, host='0.0.0.0', port=port)
